{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Computação Bayesiana Aproximada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - Hipóteses de variabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variabilidade masculina é maior;\n",
    "\n",
    "- Conclusão tendênciosa, e evidências da hipótese de variabilidade são fracas;\n",
    "\n",
    "- O conjunto de dados do Sistema de Vigilância de Fatores Comportamentais, inclui respostas de 154407 homens e 254722 mulheres:\n",
    "\n",
    "    - Para as mulheres:\n",
    "        - A altura média é 163 cm;\n",
    "        - O desvio padrão é 7,3 cm;\n",
    "        - O coeficiente de variação é 0,0444;\n",
    "\n",
    "\n",
    "    - Para os homens:\n",
    "        - A altura média é 178 cm; \n",
    "        - O desvio padrão é 7,7 cm;\n",
    "        - O coeficiente de variação é 0,0433;\n",
    "\n",
    "- Vou seguir algumas etapas:\n",
    "    - Começaremos com a implementação mais simples;\n",
    "    - Ao calcular probabilidades sob uma transformação de log, podemos escalar até o tamanho total do conjunto de dados, mas a computação fica lenta.\n",
    "    - **Computação Bayesiana Aproximada** (ABC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 - Média e desvio padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuição conjunta para estimar os parâmetros de uma distribuição gaussiana: a média, mu e o desvio padrão, sigma;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinkbayes\n",
    "class Height(thinkbayes.Suite, thinkbayes.Joint):\n",
    "\n",
    "    def __init__(self, mus, sigmas):\n",
    "        pairs = [(mu, sigma) \n",
    "                 for mu in mus\n",
    "                 for sigma in sigmas]\n",
    "\n",
    "        thinkbayes.Suite.__init__(self, pairs)\n",
    "        \n",
    "    def Likelihood(self, data, hypo):\n",
    "        x = data\n",
    "        mu, sigma = hypo\n",
    "        like = thinkbayes.EvalGaussianPdf(x, mu, sigma)\n",
    "        return like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A distribuição a priori é uniforme para todos os pares (mu, sigma).\n",
    "- Dados os valores hipotéticos de mu e sigma, calculamos a verossimilhança de um valor específico, x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- faixas apropriadas para mus e sigmas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPriorRanges(xs, num_points, num_stderrs=3.0):\n",
    "\n",
    "    # compute m and s\n",
    "    n = len(xs)\n",
    "    m = numpy.mean(xs)\n",
    "    s = numpy.std(xs)\n",
    "\n",
    "    # compute ranges for m and s\n",
    "    stderr_m = s / math.sqrt(n)\n",
    "    mus = MakeRange(m, stderr_m, num_stderrs)\n",
    "\n",
    "    stderr_s = s / math.sqrt(2 * (n-1))\n",
    "    sigmas = MakeRange(s, stderr_s, num_stderrs)\n",
    "\n",
    "    return mus, sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **xs** é o conjunto de dados;\n",
    "- **num_points** é o número desejado de valores no intervalo;\n",
    "- **num_stderrs** é a largura do intervalo em cada lado da estimativa, em número de erros padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeRange(estimate, stderr, num_stderrs):\n",
    "    spread = stderr * num_stderrs\n",
    "    array = numpy.linspace(estimate-spread, estimate+spread, num_points)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 - Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(xs, num_points):\n",
    "    mus, sigmas = FindPriorRanges(xs, num_points)\n",
    "    suite = Height(mus, sigmas)\n",
    "    suite.UpdateSet(xs)\n",
    "    print(suite.MaximumLikelihood())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 - A distribuição posteriori de CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A partir da distribuição posteriori de mu e sigma;\n",
    "- Calculamos a distribuição de CV para homens e mulheres; \n",
    "- A probabilidade de que um exceda o outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoefVariation(suite):\n",
    "    pmf = thinkbayes.Pmf()\n",
    "    for (mu, sigma), p in suite.Items():\n",
    "        pmf.Incr(sigma/mu, p)\n",
    "    return pmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algums problemas:\n",
    "    - Problemas computacionais devido às limitações sobre ponto flutuante;\n",
    "    - Presença de valores extremos;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 - Subfluxo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **subfluxo**: Valor muito pequeno que não pode ser representado por um número de ponto flutuante; portanto, é arredondado para zero;\n",
    "\n",
    "- Algumas soluções:\n",
    "    - Renormalizar após cada atualização ou após cada lote de 100;\n",
    "    - Calcular as verossimilhança sob uma transformação de log;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Pmf\n",
    "\n",
    "    def Log(self):\n",
    "        m = self.MaxLike()\n",
    "        for x, p in self.d.iteritems():\n",
    "            if p:\n",
    "                self.Set(x, math.log(p/m))\n",
    "            else:\n",
    "                self.Remove(x)\n",
    "\n",
    "    def Exp(self):\n",
    "        m = self.MaxLike()\n",
    "        for x, p in self.d.iteritems():\n",
    "            self.Set(x, math.exp(p-m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Log Verossimilhança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLikelihood(self, data, hypo):\n",
    "    x = data\n",
    "    mu, sigma = hypo\n",
    "    loglike = scipy.stats.norm.logpdf(x, mu, sigma)\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(xs):\n",
    "    suite.Log()\n",
    "    suite.LogUpdateSet(xs)\n",
    "    suite.Exp()\n",
    "    suite.Normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7 - Um pouco de otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.8 - ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A motivação por trás do ABC é que a probabilidade de qualquer conjunto de dados específico é:\n",
    "    - Muito pequeno, especialmente para conjuntos de dados grandes, por isso tivemos que usar a transformação de log;\n",
    "    - Caro para calcular, é por isso que tivemos que fazer tanta otimização;\n",
    "    - Não é realmente o que queremos de qualquer maneira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É mais relevante perguntar: \"Se amostrarmos 100 mil pessoas de uma população com valores hipotéticos de µ e σ, qual seria a chance de coletar uma amostra com a média e variância observadas?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para uma distribuição Gaussiana (µ, σ)\n",
    "    - A distribuição da média é uma gaussiana com os parâmetros µ e $\\frac{σ}{\\sqrt n}$.\n",
    "    - a distribuição do desvio padrão é uma gaussiana com os parâmetros σ e $\\frac{σ}{\\sqrt(2(n −1))}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogUpdateSetABC(self, data):\n",
    "    xs = data\n",
    "    n = len(xs)\n",
    "\n",
    "    # compute sample statistics\n",
    "    m = numpy.mean(xs)\n",
    "    s = numpy.std(xs)\n",
    "\n",
    "    for hypo in sorted(self.Values()):\n",
    "        mu, sigma = hypo\n",
    "\n",
    "        # compute log likelihood of m, given hypo\n",
    "        stderr_m = sigma / math.sqrt(n)\n",
    "        loglike = EvalGaussianLogPdf(m, mu, stderr_m)\n",
    "\n",
    "        #compute log likelihood of s, given hypo\n",
    "        stderr_s = sigma / math.sqrt(2 * (n-1))\n",
    "        loglike += EvalGaussianLogPdf(s, sigma, stderr_s)\n",
    "\n",
    "        self.Incr(hypo, loglike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.9 - Estimatição robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Há vários outliers neste conjunto de dados que quase certamente são erros;\n",
    "- Não é impossível que esses valores estejam corretos, mas é improvável;\n",
    "\n",
    "- Poderíamos usar a mediana e a faixa inter-quartil (IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MedianIPR(xs, p):\n",
    "    cdf = thinkbayes.MakeCdfFromList(xs)\n",
    "    median = cdf.Percentile(50)\n",
    "\n",
    "    alpha = (1-p) / 2\n",
    "    ipr = cdf.Value(1-alpha) - cdf.Value(alpha)\n",
    "    return median, ipr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converter de **ipr** para uma estimativa de sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MedianS(xs, num_sigmas):\n",
    "    half_p = thinkbayes.StandardGaussianCdf(num_sigmas) - 0.5\n",
    "\n",
    "    median, ipr = MedianIPR(xs, half_p * 2)\n",
    "    s = ipr / 2 / num_sigmas\n",
    "\n",
    "    return median, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dist_contorno_man.png)![](dist_contorno_woman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.10 - Quem é mais variável?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dist_var_man_woman.png)\n",
    "- Distribuição posterior do CV\n",
    "- O coeficiente de variação é maior para homens do que para mulheres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A média para os homens é 0,0410; \n",
    "- A média para as mulheres é 0,0429."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Com num_sigmas=1, concluímos que as mulheres são mais variáveis;\n",
    "- Com num_sigmas=2, concluímos que os homens são mais variáveis;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avaliação da hipótese de variabilidade depende da interpretação da “variabilidade”:\n",
    "    - num_sigmas=1, focamos nas pessoas próximas à média;\n",
    "    - Com o aumento de num_sigmas, damos mais peso aos extremos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
